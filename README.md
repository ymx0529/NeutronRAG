# ğŸ”¨Setup

```bash


# åˆ›å»ºcondaç¯å¢ƒï¼špython >= 3.10
conda create --name llmrag python=3.10.14 -y

conda activate llmrag

# å®‰è£…ç›¸å…³çš„pythonåŒ…ï¼š
pip install -r requirements.txt

```

# æµ‹è¯•OLlamaæ˜¯å¦å¯ç”¨ï¼š
```bash
ollama run llama2:7b
```


ğŸ“¦ éƒ¨ç½²å›¾æ•°æ®åº“
1. NebulaGraph Installation Guide
Step 1: Install docker-compose
Ensure that you have docker-compose installed. If not, you can install it with the following command:

```bash
sudo apt install docker-compose
```
Step 2: Clone NebulaGraph Docker Compose Repository
In a directory of your choice, clone the NebulaGraph Docker Compose files:

```bash
git clone https://github.com/vesoft-inc/nebula-docker-compose.git
cd nebula-docker-compose
```
Step 3: Start NebulaGraph
In the nebula-docker-compose directory, run the following command to start NebulaGraph:

```bash
docker-compose up -d
```
Step 4: Check NebulaGraph Container Status
After starting, you can verify that the NebulaGraph container is running by using:

```bash
docker ps
```
Step 5: Connect to NebulaGraph
To connect to NebulaGraph inside the container, use the following command:

```bash
nebula-console -u <user> -p <password> --address=graphd --port=9669
#Replace <user> and <password> with the actual username and password. Ensure that port 9669 is used for the default configuration.
```
Step 6: Enable Data Persistence
To ensure that data persists even after the container is restarted, you can mount persistent volumes. Either modify the volumes section in the docker-compose.yaml file, or manually run the following command with specified persistence paths:

```bash
docker run -d --name nebula-graph \
    -v /yourpath/nebula/data:/data \
    -v /yourpath/nebula/logs:/logs \
    -p 9669:9669 \
    vesoft/nebula-graphd:v2.5.0
#Replace /yourpath/nebula with your actual data persistence path.
```




2. Neo4j(æš‚æ—¶å¯ä»¥ä¸å®‰è£…)






# ğŸ’„Run 
```
#é…ç½®ä¸´æ—¶ç¯å¢ƒå˜é‡ç¯å¢ƒ
ä¾‹å­ export PYTHONPATH=$PYTHONPATH:/home/lipz/RAGWebUi/RAGWebUi_demo/backend
export PYTHONPATH=$PYTHONPATH:/your/path/backend

```

```
# æ‰§è¡Œä¸€ä¸ªweiuiï¼Œä»¥æ˜¾ç¤ºå‰ç«¯ç½‘é¡µï¼š 
python webui_chat.py

# ä½¿ç”¨å¦ä¸€ä¸ªç»ˆç«¯æ‰§è¡Œä¸€ä¸ªå›¾çš„ç½‘é¡µï¼Œç”¨æ¥åœ¨å‰ç«¯ç½‘é¡µä¸­æ˜¾ç¤ºå›¾æ‹“æ‰‘ï¼š
python graph.py
```

```
# ä½¿ç”¨åç«¯æ‰§è¡Œä¸»è¦ä¸ºäº†åšä¸€äº›ç ”ç©¶å·¥ä½œï¼š
python backend_chat.py --dataset_name "rgb" --llm "llama2:7b" --func "Graph RAG" --graphdb "nebulagraph" --vectordb "MilvusDB"
```

# Notion

1. ç°åœ¨å¼ƒç”¨äº†.envæ–‡ä»¶çš„è¯»å–æ–¹å¼ï¼Œæ”¹ä¸ºå®¢æˆ·ç«¯è¾“å…¥ã€‚åŒ…æ‹¬å¤§æ¨¡å‹çš„åå­—
2. ./llmragenv/llmrag_env.py ä¸­ï¼Œæœ‰ä¸€ä¸ªlow_chatçš„æ–¹æ³•ï¼Œè¿™ä¸ªæ˜¯ä¸€ä¸ªé˜‰å‰²çš„è¾“å…¥ï¼Œå¤§æ¨¡å‹çš„åå­—ã€æ•°æ®åº“çš„ä½¿ç”¨ç­‰å‚æ•°ç›´æ¥åœ¨è¿™é‡ŒæŒ‡å®šäº†ï¼›è€Œweb_chatæ˜¯ä¸€ä¸ªå…¨çš„ç‰ˆæœ¬
3. å…³äºå¤§æ¨¡å‹çš„æ”¯æŒï¼šåœ¨llm_factoryä¸­ç”±llm_providerå­—å…¸ï¼ŒåŒ…å«äº†ç°åœ¨æ”¯æŒçš„è¿è¡Œåœ¨æœ¬åœ°çš„å¤§æ¨¡å‹ã€‚ï¼ˆå› ä¸ºä½¿ç”¨å•†ç”¨å¤§æ¨¡å‹çš„api_keyä»˜è´¹ï¼Œè¿™é‡Œæš‚æ—¶ä¸å¼€æ”¾ï¼Œä½†å¯ä»¥è‡ªå·±å»ä¹°ï¼Œç›¸å…³é…ç½®åœ¨./config/config-local.ymalï¼‰
4. ç½‘é¡µç«¯å£ä¸æ•°æ®åº“ç›¸å…³é…ç½®åœ¨./config/config-local.ymalè¿›è¡Œæ›´æ”¹ï¼ˆå‘é‡æ•°æ®åº“ä¸nebulagraphåœ¨ä»£ç é‡ŒæŒ‡å®šï¼Œè¿™é‡Œéœ€è¦é‡æ„ï¼‰
5. ä»£ç æ¶æ„ï¼š
![avatar](./resource/codestruc/codestruc.bmp)


# é—®é¢˜ï¼š
web_chat()ä¸­è™½ç„¶å¯ä»¥æŒ‡å®šæ¯æ¬¡èŠå¤©çš„å¤§æ¨¡å‹ï¼Œä½†æ˜¯é—®é¢˜æ˜¯å¯åŠ¨ç½‘é¡µä¹‹ååªæœ‰ç¬¬ä¸€æ¬¡çš„è¾“å…¥æ˜¯æœ‰ç”¨çš„ï¼Œåç»­å¤§æ¨¡å‹éƒ½åªç”¨æœ€å¼€å§‹é€‰çš„é‚£ä¸ªã€‚
# ä»£ç ç»“æ„ï¼š

Chat:
/<yourpath>/RAGWebUi_demo/chat
graphragå’Œvectorrag




# Reference
[Meet-libai from BinNong](https://github.com/BinNong/meet-libai)